{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4sQLvZopn3C"
      },
      "source": [
        "phase one (if else )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weogAib765F8"
      },
      "outputs": [],
      "source": [
        "def Kepler_reply(user):\n",
        "    if 'hi' in user:\n",
        "        return 'hey how are you?'\n",
        "    elif 'fine' in user:\n",
        "        return 'nice , what about you'\n",
        "    elif \"who are you\" in user:\n",
        "        return \"I am your personal AI assistant \u00e2\u20ac\u201c a lite version of kepler.\"\n",
        "    elif \"thank you\" in user:\n",
        "        return \"Always at your service, Sir.\"\n",
        "    elif \"bye\" in user:\n",
        "        return \"Goodbye Sir. Awaiting your next command.\"\n",
        "    else:\n",
        "        return \"Apologies Sir, I didn't quite understand that. Could you please rephrase?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h8kV7l1plWM"
      },
      "source": [
        "phase two (detect the emotion )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jn9mGvZJudQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "f2c2fc765a364538b793c2fe1babee71",
            "e273888fa81a4d2c9a87575ed60e0445",
            "6e5cef03e34647898b60ce8cadb11ef9",
            "c7a36729e3ac4f3299b5bcf793f27c38",
            "6678c1add2f54bba8897330063eac52b",
            "954fd9b5a36e48ddb380d9195fc3b85f",
            "75e76b50e06b420cb9498ce9b835f552",
            "bbccdfaa649640b6b483b18f7a4476ad",
            "9c72da2416304ad08dac1eae50f44fce",
            "b469a821ef90419489eb2827049ce686",
            "dbdfbbd0b5954c61a7c9c560406d0670",
            "95c26bc216f2409d87f7bb9fbb6e9fc6",
            "a4c8fffd02b046d58c7e7f3e95d350d0",
            "e48814567bc643a5af5a366b55d1acc4",
            "fa4ceb7f182349abb36b4ef10c7c7c94",
            "933fc45776034cc090c1e178328e9377",
            "d5389af1566348c19c04e24f97391da8",
            "f59dea21068742b7887267ea98ae312e",
            "4fb97982d1e746b1b4096cbf68ece9f0",
            "ad434f651a1449008609a83daaed6d08",
            "2ae642c6195e48b89d1ffe91e8494d30",
            "2f5cc011d1db47bcb3512a9316aa816c",
            "b832f6e96d744fb2b6e12827c55e6d7a",
            "3b683cb71d6c49289808dd467ba4c5cf",
            "85898d0c758841928d58e455f99cfba0",
            "92e876d59f9c41f49e034fb9c667eb2c",
            "039625d4ac204870bb8f2d2f0b674e26",
            "bce752d7c19d49029191971789db4d65",
            "b4f256b3055c4b6083b9e38374164ef1",
            "ae0bee46ac8d4bcc9750a61fad40e9ae",
            "087954596c58463a87890db49d2d1e1a",
            "1a0ef817b7294be89603da08bc280d85",
            "556677e28b8b439886c3a07e0027bc00",
            "bd42717396a74592bf5b2d35f8d1b39a",
            "95734b486e2a4cc4ae979622fd3f62af",
            "570b6a3d37da41b9abc0ba33dde1012d",
            "3b5c1e8737bc42fc8a9a809047bad234",
            "c600fb31178545c6b216267f1f5b96fc",
            "58fb0d880ecd4152abd7ba6e05a251ad",
            "16c5bb6f420c479da9e330cdddcc47ca",
            "d620465c66c748c2841130e44e7985f2",
            "53731c767ed04b24a0b41e6467c24db7",
            "6b486edae1e84749b61fde626b859ee0",
            "6b4b49f8f8814cb7b40acfa3f037ee99",
            "0eb000c85ba14a4695d6f8f63b878491",
            "9322fd07ddd84054a461f3ac78771e20",
            "cada784f44844dc199a2346fcebc4380",
            "2532812fa9404fd79aefe7565d957fd7",
            "5e495cccd8e2447e8520e84f91efa77f",
            "bcd1a18a1eb745e095aa5c611f2960de",
            "9532e4bb35c14391b27e22c664688e53",
            "d025e5efc6064daf98927b44c427ccba",
            "8644813d9c58403facb6980bdfd81217",
            "fdbc4c2bad28413cbaf8e28300aba44d",
            "6befe001b96f48f29bbe882bcc6512e8",
            "01e76656fbeb4a8e86f273a2c3866090",
            "cdaf132a50984a4cbf85edada5d42cf8",
            "e82086747ca44bf29c6653a585e025b1",
            "88118c27b7df432ba4e7d46d5549775b",
            "9a3a7df8269d44189cf676e0663a5520",
            "916c3230696349e7991ba1fb839edfbf",
            "2d26356be2e9458f866ded998efe4bdd",
            "03cb314bac564f2f996f6258c8580195",
            "38ccf0e01599477cbc744c14e7f006e5",
            "05a575684360497ca11677befc2aa4c6",
            "2aa114be21c04eafa42bd1812aa20a55",
            "e51d3aff82dd492f9c28125d32b5b17b",
            "8db1086f83e54d6ab4669d3e79c9479b",
            "84e1446111134371b956e03d67e1d912",
            "4f075c11aab841efba0aa345d495893c",
            "b9a0a97381af459690ce26bfd80f5976",
            "ef6f8bef9cd6429c9e6bf2c2dc8691b7",
            "62427c8c7c7d42e7b9f03305e6e272c4",
            "5b90873b756e4351a913d23e861219d7",
            "5e49c24ff1704fe0a3a132f47d2acdce",
            "43ac87c6533443efae2a2e32a39d5f3e",
            "0c9320be3a0a4635a57aca8666ad1831"
          ]
        },
        "id": "B1zD_DSGJy7h",
        "outputId": "d118817b-5e07-4ca6-9255-41e5e83c8974"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2c2fc765a364538b793c2fe1babee71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95c26bc216f2409d87f7bb9fbb6e9fc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b832f6e96d744fb2b6e12827c55e6d7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd42717396a74592bf5b2d35f8d1b39a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0eb000c85ba14a4695d6f8f63b878491",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01e76656fbeb4a8e86f273a2c3866090",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e51d3aff82dd492f9c28125d32b5b17b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load pre-trained model & tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")  # convert text into tokens\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"j-hartmann/emotion-english-distilroberta-base\")  # pre trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4_8NBueKja3"
      },
      "outputs": [],
      "source": [
        "# Define labels\n",
        "labels = ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion',\n",
        "          'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
        "          'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism',\n",
        "          'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral','sad']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kAQx4d7U8-P"
      },
      "source": [
        "we are not doing preprocessing the data like cleaning , post tagging ,etc  because transformers don't need these things transformers Are pre-trained on raw, noisy real-world text (Reddit, Wikipedia, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrujHZge657Q"
      },
      "outputs": [],
      "source": [
        "# Emotion prediction function\n",
        "def detect_emotion(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True) # pt = pytorch truncation=True ensures long texts are safely cut to model\u00e2\u20ac\u2122s max length.\n",
        "    with torch.no_grad():  # we don't need gradient decent right now\n",
        "        outputs = model(**inputs)   # giving input into the model and taking raw output\n",
        "        probs = F.softmax(outputs.logits, dim=1)  # This tells us, in % terms, how likely each emotion is (e.g., 90% sad, 5% angry).\n",
        "        top_prob, top_class = torch.max(probs, dim=1) # Finds the emotion with the highest probability.\n",
        "        emotion = labels[top_class.item()] # convert it into a plain python integer\n",
        "    return emotion, top_prob.item() # in top class we have the index of the most probibility emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AapzdFWO659e"
      },
      "outputs": [],
      "source": [
        "def kepler_reply(user_input):\n",
        "    emotion, confidence = detect_emotion(user_input)\n",
        "    print(f\"[Emotion: {emotion}, Confidence: {confidence:.2f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e528173396284ef8a8c98f6e66fb2e58",
            "d5c3c0f73f59484da2572dc44c6ad148",
            "48fa5f97df7649dbab85a2afb44e5a66",
            "3e04429e178d41249652f5972ddb1825",
            "c590408b51b94a258f810551e51b1753",
            "6503d8812ae14f4886e82d269a546def",
            "a632895a514b4b2bb6265dd739c12935",
            "16264267d12c4a7a834bd9f0042b6e47",
            "30d974ca92784bb78221337663dbc289",
            "bd210d8a6b3849908777b8428fc8a7e4",
            "2a925a1533914eafbbf1da9d61ede1c1"
          ]
        },
        "id": "RBC5VgMj65-x",
        "outputId": "28b4f4ae-9898-48c1-fc77-6fc732ae85c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e528173396284ef8a8c98f6e66fb2e58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/329M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Emotion: caring, Confidence: 0.90]\n"
          ]
        }
      ],
      "source": [
        "kepler_reply(\"They passed away last night\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du1CTiHVpydI"
      },
      "source": [
        "phase 3 ( Detect the purpose (intent) of the user's message )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-uUncna66DW"
      },
      "outputs": [],
      "source": [
        "def detect_intent(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    intents = {\n",
        "        \"greet\": [\"hello\", \"hi\", \"hey\", \"good morning\", \"good evening\"],\n",
        "        \"goodbye\": [\"bye\", \"see you\", \"take care\", \"later\"],\n",
        "        \"thanks\": [\"thank you\", \"thanks\", \"appreciate it\"],\n",
        "        \"joke\": [\"joke\", \"make me laugh\", \"tell me something funny\"],\n",
        "        \"motivation\": [\"motivate\", \"inspire me\", \"i need motivation\", \"encourage\"],\n",
        "        \"weather_query\": [\"weather\", \"temperature\", \"forecast\", \"rain\", \"sunny\"]\n",
        "    }\n",
        "\n",
        "    for intent, keywords in intents.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in text:\n",
        "                return intent\n",
        "    return \"unknown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTtDnk3O6O30"
      },
      "outputs": [],
      "source": [
        "# emotion_mapper.py logic in a cell\n",
        "emotion_map = {\n",
        "    \"sadness\": \"sad\", \"grief\": \"sad\", \"remorse\": \"sad\", \"disappointment\": \"sad\",\n",
        "    \"embarrassment\": \"sad\", \"caring\": \"sad\",\n",
        "    \"joy\": \"happy\", \"love\": \"happy\", \"amusement\": \"happy\", \"excitement\": \"happy\",\n",
        "    \"optimism\": \"happy\", \"relief\": \"happy\", \"admiration\": \"happy\", \"gratitude\": \"happy\",\n",
        "    \"pride\": \"happy\", \"approval\": \"happy\",\n",
        "    \"anger\": \"angry\", \"annoyance\": \"angry\", \"disapproval\": \"angry\", \"disgust\": \"angry\",\n",
        "    \"fear\": \"anxious\", \"nervousness\": \"anxious\",\n",
        "    \"surprise\": \"surprised\", \"realization\": \"surprised\",\n",
        "    \"confusion\": \"confused\", \"curiosity\": \"curious\", \"desire\": \"curious\",\n",
        "    \"neutral\": \"neutral\"\n",
        "}\n",
        "\n",
        "def simplify_emotion(emotion):\n",
        "    return emotion_map.get(emotion, \"neutral\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVKX43mz66E9"
      },
      "outputs": [],
      "source": [
        "def kepler_reply(user_input):\n",
        "    raw_emotion, confidence = detect_emotion(user_input)\n",
        "    emotion = simplify_emotion(raw_emotion)\n",
        "    intent = detect_intent(user_input)\n",
        "\n",
        "    if intent == \"greet\":\n",
        "        return f\"Hello Sir. You seem {emotion} today. How may I assist you?\"\n",
        "    elif intent == \"joke\":\n",
        "        return \"Why don\u00e2\u20ac\u2122t scientists trust atoms? Because they make up everything. \u00f0\u0178\u02dc\u201e\"\n",
        "    elif intent == \"motivation\":\n",
        "        return \"Sir, you weren\u00e2\u20ac\u2122t born to be average. Let\u00e2\u20ac\u2122s rise and grind.\"\n",
        "    elif intent == \"weather_query\":\n",
        "        return \"Apologies Sir, I\u00e2\u20ac\u2122m not connected to live weather yet. Want me to add that?\"\n",
        "    elif intent == \"thanks\":\n",
        "        return \"At your service, always.\"\n",
        "    elif intent == \"goodbye\":\n",
        "        return \"Goodbye Sir. Jarvis is on standby.\"\n",
        "\n",
        "    # Emotion-aware fallback\n",
        "    if emotion == \"sad\":\n",
        "        return \"You seem down today, Sir. Want a joke or a pep talk?\"\n",
        "    elif emotion == \"happy\":\n",
        "        return \"You're glowing with energy today, Sir. Let's conquer something!\"\n",
        "    elif emotion == \"angry\":\n",
        "        return \"Anger detected. Would you like to vent or cool off with humor?\"\n",
        "    elif emotion == \"anxious\":\n",
        "        return \"Breathe deeply, Sir. Everything is under control. I'm here.\"\n",
        "    elif emotion == \"surprised\":\n",
        "        return \"Seems like something caught you off guard. Want to talk about it?\"\n",
        "    else:\n",
        "        return f\"I sensed {emotion}, Sir. What shall we do next?\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xi0LH-n7N7U"
      },
      "source": [
        "phase 4 ( use a small, fast transformer model to generate empathy text.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "dfb61afa669f4d6d8ca8749d4cf2a490",
            "56390e925b6449d0b7d43cefaa03287e",
            "f2c66e23fdd3457ba6973174022dd7d6",
            "3ac52aa604834d2b9eef5b006644359e",
            "02885febe56641ee944fc4fce023c884",
            "86896e78d6944dd2b8f76e183bb6c83e",
            "d5449a5803d34f4592777e2c25caa6b6",
            "4e1b97761b4c4b42bc811ac4a5290c86",
            "65e5a3bbe16b4f84a7904884574b4d2e",
            "1a9e3fd6dd3646c0ac44c7523458bdde",
            "a9a2ebaaa5ab410c8b546ae397fb1716",
            "e89f6346b25747e7acc8165743adaf9f",
            "f3063b31e8af4df196afb78f7bcc6a2d",
            "ef00e3ff2aa143cc899b63b0c99e8c3c",
            "10151ef32264464d8c0cb14e6574efc1",
            "18d0e559ad574ab29f9c77bc0f34b3fc",
            "a8dd324f79a9421eaf25e4c3a419b5ed",
            "7f2481e6b4894d9fb24dfb27a266dd82",
            "aa056d85915449d48eb30d017580a55d",
            "25f9ea2effac4b4f91a3eaa0e1e3e0ce",
            "9f5338139d1f4bc8aaaf350780530423",
            "c918106662744c978282ef56d303fa49",
            "d67df62ce8d347ea9d940b5a5a7345fc",
            "b45f403a0a6946e5b2bde039b7f155f9",
            "02af7ee5b01448b7b3230d019f6dc447",
            "949cd1bd82a94ce3a15d2c1487d7e07a",
            "8cfabddba5c94077ac63fcd70a1fb2f2",
            "6d94f138fd12456aa0444bb1af57f6ba",
            "aa1daaf6276645bf9cf282187958b6e6",
            "bf481810393640e2b00a271dd90bb652",
            "8025bd64f8564e42a5b2da45f989958d",
            "b505dc2b67b9424492f26ad9ae074c1d",
            "635d3a1dc2bb480aa5b24eff56df4ae9",
            "1a15626279804aaf85bac17bd3e6d442",
            "4072828cbab448e1a5988ae6cbe8ea8c",
            "03a73106a0b74e3b932f5dbbe8ed495f",
            "86fa4ed702a148aea31c6ede86c9d509",
            "2694aff8ef074368bc2f74fed911e1d9",
            "4a5e0f7fb9fc4f1b9c28dfa92a57d48c",
            "1efa43a0725e4d20b2e268c88342f00f",
            "1e078a8a6e5244158ef6769a7f76e5aa",
            "88c8847c601943abb7f80646cfce1904",
            "1a35b3f5675d4b0aa34179206ad250f8",
            "4c2f181e87124abf92e2926f8bd124ff",
            "00671dfb7e2a45e389c285f4ae529ebd",
            "5af5488fbc064a8ea39ab9ad73d6c267",
            "8fbce3a509b94d89821d5beb3762774a",
            "e5fa59f36a1645a5818f34c80e42edae",
            "46c14dac47d24a4a96dc50a87cba8a5a",
            "7d58fadc04c346eca7b34bc1ad5700e4",
            "116d68756a3a41238da1816be89dadcd",
            "76ac916693cc4c468b4e5dc9bec0fd47",
            "f210f66b41dc48c9a67ecd09b4e18780",
            "cbedf4ec4a7e486f8fb62d7888b7d33c",
            "1e22a70145f143f6871219891791b21e",
            "c994b9d4cb9c420cab0ec2ecaf92dcfc",
            "4c41d64f82c341e48298006a688458d2",
            "0de7da25afb446eeb95862049d2c1d74",
            "559c393fcd304a5398842e1b5f71c6ed",
            "16448efbf2564f83b27f26ca126ac4f2",
            "e165a74eed814b37aac126b647ce461f",
            "032e01180265407eb655b792278be6e7",
            "211feaff9bce47e791ce702e7259f39c",
            "062efd215c1f4ded9674a921b0b95cc2",
            "9ceef9316dc04fe4b0d5fab853799048",
            "cd0ea6ff6ae844b5b36e41bb835dd55d",
            "1e7f35b139d14ec3b15dc6e89c428545",
            "f5b0070ee8334d01a75d9f4d4a0f7c84",
            "6d8eb22281494afcb7d077b64d011a9c",
            "67edc32e74b84e028aaeb4d074d115b9",
            "b123028a37434da5a78ce64e839ac248",
            "21b31d0ad138490a90d442acf09bad8a",
            "db07891a241b4844bdd9338f4a6cf074",
            "1736387f9e5a41c0907f4788ef907f0b",
            "1179b3bba6064edcab479be2335b79df",
            "07d901add6b647159fc623a6e8b8e3a0",
            "5f4b02994e6d467bb16bccc134e62f90"
          ]
        },
        "id": "_Vyve5Eb66XC",
        "outputId": "68c0f547-d228-4987-aa86-ad4d028891ec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfb61afa669f4d6d8ca8749d4cf2a490",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e89f6346b25747e7acc8165743adaf9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d67df62ce8d347ea9d940b5a5a7345fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a15626279804aaf85bac17bd3e6d442",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00671dfb7e2a45e389c285f4ae529ebd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c994b9d4cb9c420cab0ec2ecaf92dcfc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e7f35b139d14ec3b15dc6e89c428545",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# using light weight gpt model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load GPT-2 tokenizer & model\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "gen_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9V8Hcml66ZY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def generate_response(intent, emotion, max_length=50):\n",
        "    # Base prompt styling\n",
        "    style_prompt = f\"As kepler, respond to a human who feels {emotion} and just said something related to {intent}. Keep it supportive, intelligent, and a little witty:\\n\\n\"\n",
        "\n",
        "    inputs = gen_tokenizer.encode(style_prompt, return_tensors=\"pt\")  # We convert our prompt into token IDs (numbers) that the model understands.\n",
        "    outputs = gen_model.generate(inputs, max_length=max_length, pad_token_id=gen_tokenizer.eos_token_id, do_sample=True, top_k=50, top_p=0.95)\n",
        "\n",
        "    generated_text = gen_tokenizer.decode(outputs[0], skip_special_tokens=True)  # converting into text\n",
        "    reply = generated_text[len(style_prompt):].strip() #  This trims off the **original prompt** from the output to give you **only Jarvis's reply**.\n",
        "  # \"Start slicing the text from the character index after the end of the prompt.\"\n",
        "\n",
        "    return reply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOdTQdAs66bq"
      },
      "outputs": [],
      "source": [
        "def kepler_reply(user_input):\n",
        "    raw_emotion, confidence = detect_emotion(user_input)\n",
        "    emotion = simplify_emotion(raw_emotion)\n",
        "    intent = detect_intent(user_input)\n",
        "\n",
        "    # Generate smarter response if intent is known\n",
        "    if intent != \"unknown\":\n",
        "        smart_reply = generate_response(intent, emotion)\n",
        "        return f\"{smart_reply} \\n\\n[Detected: {intent}, {emotion}, Confidence: {confidence:.2f}]\"\n",
        "\n",
        "    # Fallback response for unknown intent\n",
        "    return f\"I sensed you're feeling {emotion}, but I didn't quite get what you need. Could you rephrase it?\\n\\n[Confidence: {confidence:.2f}]\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WicSNFf2C0J0"
      },
      "source": [
        "Phase 5: memory phase , kepler remember past conversations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIvX6Emj66de"
      },
      "outputs": [],
      "source": [
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKuUUdgJ66ff"
      },
      "outputs": [],
      "source": [
        "# kepler short-term memory\n",
        "emotion_history = deque(maxlen=5)\n",
        "intent_history = deque(maxlen=5)\n",
        "conversation_history = deque(maxlen=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKYS5lYS66hh"
      },
      "outputs": [],
      "source": [
        "def kepler_reply(user_input):\n",
        "    raw_emotion, confidence = detect_emotion(user_input)\n",
        "    emotion = simplify_emotion(raw_emotion)\n",
        "    intent = detect_intent(user_input)\n",
        "\n",
        "    #  Store memory\n",
        "    emotion_history.append(emotion)\n",
        "    intent_history.append(intent)\n",
        "    conversation_history.append({\"user\": user_input, \"emotion\": emotion, \"intent\": intent})\n",
        "\n",
        "    # Context-aware logic\n",
        "    if intent == \"greet\":\n",
        "        return f\"Hello again, Sir. You seem {emotion} today. Last time you were {emotion_history[-2] if len(emotion_history) > 1 else 'neutral'}.\"\n",
        "    elif intent == \"motivation\":\n",
        "        if \"sad\" in list(emotion_history)[-3:]:\n",
        "            return \"I know it\u00e2\u20ac\u2122s been tough lately, Sir. But remember\u00e2\u20ac\u201ddiamonds form under pressure. \"\n",
        "        else:\n",
        "            return \"Rise and grind, Sir. You\u00e2\u20ac\u2122re built for greatness.\"\n",
        "    elif intent == \"joke\":\n",
        "        return \"Let\u00e2\u20ac\u2122s lighten the mood: Why did the AI get promoted? Because it had deep learning. \"\n",
        "    elif intent == \"thanks\":\n",
        "        return \"You're welcome, Sir. I'm always learning from you.\"\n",
        "    elif intent == \"goodbye\":\n",
        "        return \"Goodbye, Sir. I'll remember this session until next time.\"\n",
        "\n",
        "    # Emotion-aware fallback\n",
        "    if emotion == \"sad\":\n",
        "        return \"Still feeling a bit down, Sir? I'm right here if you want to talk or laugh.\"\n",
        "    elif emotion == \"happy\":\n",
        "        return \"Your energy is infectious, Sir. Let\u00e2\u20ac\u2122s channel it!\"\n",
        "    elif emotion == \"angry\":\n",
        "        return \"You\u00e2\u20ac\u2122ve had a tough moment, Sir. Want to vent or distract yourself?\"\n",
        "    else:\n",
        "        return f\"I sense {emotion}, Sir. What would you like me to help with?\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYFn698uJuUZ"
      },
      "source": [
        "Phase 6 : voice (we cannot integrate the voice into google colab )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU1q4c4nDNCG"
      },
      "outputs": [],
      "source": [
        "# def speak(text):\n",
        "#     tts = gTTS(text=text, lang='en')  # gTTS (Google Text-to-Speech) library to convert the text into speech.\n",
        "#     tts.save(\"kepler_output.mp3\")    # This file contains the spoken version of your text.\n",
        "#     return ipd.Audio(\"kepler_output.mp3\", autoplay =True)  # load and play the audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrAXTKEdyDun"
      },
      "outputs": [],
      "source": [
        "# response = kepler_reply(\"Tell me a joke\")\n",
        "# print(response)\n",
        "# speak(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy5hY3_CSCkw"
      },
      "source": [
        "FINE TUNING THE LLM with LORA with my own dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "2P9etJRMSCFG",
        "outputId": "254c034f-71fd-4b82-cea6-2a926db5058a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-14f3519f-60b2-49a8-b7aa-f2bf6fbe33bf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-14f3519f-60b2-49a8-b7aa-f2bf6fbe33bf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving jarvis_cleaned.txt to jarvis_cleaned.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()            # uploading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_zugB4PCSCLp"
      },
      "outputs": [],
      "source": [
        "#converting the dataset into hugging face dataset\n",
        "\n",
        "from pathlib import Path\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load the raw text\n",
        "lines = Path(\"jarvis_cleaned.txt\").read_text(encoding='utf-8').strip().split(\"\\n\\n\")\n",
        "\n",
        "# Wrap each pair as a dict (1 line = 1 sample)\n",
        "data = [{\"text\": line.strip()} for line in lines if line.strip()]\n",
        "\n",
        "# Create Hugging Face-compatible dataset\n",
        "dataset = Dataset.from_list(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wCslGxhSCOR",
        "outputId": "5211dc64-5af3-4734-8e53-7969149a6dff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': \"### User: I feel overwhelmed by everything happening in my life.\\n### Jarvis: Storms don't last forever, Sir. Your mind is stronger than this moment believes.\"}\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "b28ae2842dcf40e6bbb4692157c3bda2",
            "91dd88f0980f44708bfef30ef582872d",
            "d05579a2a0024957be824dad30fd42df",
            "0bafe85e33db4267ad289a5b1e8aaa93",
            "a6b341b108ab4a1baec2dd29b17d7d29",
            "218f4a132dd74d90ba16845469809ca3",
            "868ad98058bc47d4be43e1d6544e1ea9",
            "01b6abdc82c745f391dd36ebc940b587",
            "8a86645fb3c94479bd444be37b97fe34",
            "f4bbe3213c2e4ea8a5036e73a1668500",
            "9cf42bc688b64115b9a5b654916499bb",
            "4636c989728b471f918272250c187f70",
            "a76f09a8d32d42129d8fd8785e7226d5",
            "8fdfed0ee61c4574924ef09330e3edae",
            "157b4cbb21ca41dab9ed65a99bc4b294",
            "b42dfd4665c64e8f9448124467785eeb",
            "a720743fb05141408030b53f95c43b84",
            "5e1ee8a3e12d42379e6967bd133401e9",
            "9328042406f141c79c1019d941c36d22",
            "6fdfe7af2ecf4e14ac662250a6977e75",
            "968ce38b01444ac1be0a0b6a094bdb61",
            "4b672dfb083e48d1851ef1a034e9aacc",
            "715128e252024cee9a24f5d649f04ea6",
            "05c64b16709f48f49eac534d09cc2dd3",
            "ed97b30fd1294c62b71c3ce3bad42c46",
            "70537ca1255e4b2d9686807d75bbbce6",
            "1de477ea2e174b4dbec0a745447529e3",
            "7c78ee5d437544c4b8cb61d7f27a13de",
            "e746beab1afb40c8a0fad429c74a1e6b",
            "fc96572346a346a086c9b0133b3f4b40",
            "45de9516857b4d3bbebf967314080ced",
            "378b757132e840ad83c620e90e0e077d",
            "fccb2fdb65f04f54991191603d1b7d7a",
            "75db405d21f146e1aa2fb0a15d0fb803",
            "475fc183afcd4556b488ba382cc2d906",
            "01c9ba8622a046969eba9c7d443e4ec6",
            "eddf9a57202c4c649a910040fd137489",
            "1deffb092a0546e8802e3ba70de3e583",
            "81208db7d4f04072891fab90524f846d",
            "34711aa32d9349508e9663a1d795d237",
            "60928f71ef7244dbb7f53ea05b637c86",
            "121a6349ff7c405e9d7851d999b2e804",
            "cc5cc67ddbae424b9c42b48d9d136c5c",
            "61b0ad9e2cbf40b3ab30b234ae5ed5ba",
            "38b6ceb5ef8a4c3fb5d7957095fe9461",
            "3c96bc6e20bd479085b40bf5ef8d05e9",
            "e445c231459e486fa6d703dd57ac9e87",
            "b8974fc54283440bae14806c5fa6f346",
            "10b3469b025f442c8fce28b878ed903b",
            "344b25c12463486f895bbe140559cb73",
            "6e251568765f4c42ae07391007e627ab",
            "95c83fc62c7b4cc1ae3260c49fd6cf35",
            "9ba7a8d9a72a4e99a4bee944bf91209f",
            "96acc48196fb48f2971913526e48c18f",
            "4e0133b6949d4d61aff744e4cde04e12",
            "6fda7c9106f949929d53d3fc61ec789e",
            "6eb5b2b5e111497dbdf8b6e0bb1a26a2",
            "27bedfbadcde485791eb848169f1aea3",
            "fa3bcd3998d14d2ca3230b5ca816ef5b",
            "3174de1a439f45a0ad9b772630dd4136",
            "e93818dd434246e5ab892bcc7d9cd692",
            "3a1194978a8e4d7ea23096d6b7033a42",
            "06e933d98b974657bc05d64a0a2d5144",
            "9b73940aea5d47098b65f312f9b539c5",
            "75fc7738910848b286c5fbf2c673d478",
            "f219a42c7553438eaacbc28f83365c4e"
          ]
        },
        "id": "dfIAKpJWZlmc",
        "outputId": "91b3800d-82f2-43ab-e798-51174b86fc5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b28ae2842dcf40e6bbb4692157c3bda2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4636c989728b471f918272250c187f70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "715128e252024cee9a24f5d649f04ea6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75db405d21f146e1aa2fb0a15d0fb803",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38b6ceb5ef8a4c3fb5d7957095fe9461",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fda7c9106f949929d53d3fc61ec789e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/554 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token  # important for GPT-2 models\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(example):\n",
        "    tokens = tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256,\n",
        "    )\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    return tokens\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d9bH8JPAMmvy"
      },
      "outputs": [],
      "source": [
        "# train the model\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ff77331b8dce4fd5b817e9af38e1b18f",
            "af88d191810d47fe98aae519ec38dafe",
            "0ba2a006bf684df2b1b614734c246407",
            "7fa33781cce94e37ad7929a681de4b76",
            "0adfcf9434134c7c93bc22216b66ff38",
            "960b79060e9a4fc593e9192a5864e56f",
            "b2f3b66c339647cc9f51135e9cac5643",
            "43801165535a4d649e6a057b9e3690d8",
            "7dadedda1fa041b8805eb61619210a76",
            "49030fe292944e5abe657d499f5abb5d",
            "93e0ba8c48f74ba18e7b68a01c163b2e",
            "16ded7145f494192827b0591f231e037",
            "05cd82ba383b4338bc438c42cdab401a",
            "f24089e582594c67895611915414cc59",
            "e62f20e6e51a40a983b879190e1f2e03",
            "0db9f04137224de0acaa8306a942d1ce",
            "18d9cc23f3b74d0c831f8d0cc2939095",
            "97b88f303eeb409d8e925d67ed68df8a",
            "9a9be4f404c24482a004b9768080106a",
            "fd8be89f5463493b82403cba304da4d0",
            "4bbe645aaf2c49b9a61c58b818680183",
            "0637f45e9e534f6ab1864aef5e6b4dd3"
          ]
        },
        "id": "DDfE_63JMofv",
        "outputId": "7d9b16b8-9571-47df-c9cd-31e43e44fb77"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff77331b8dce4fd5b817e9af38e1b18f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16ded7145f494192827b0591f231e037",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load tokenizer and model\n",
        "model_id = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # important fix for GPT-2\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r8DaHOsUMqsp"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "o6Ua9haOMsDb"
      },
      "outputs": [],
      "source": [
        "# Setup LoRA config\n",
        "peft_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc3JhkenMund",
        "outputId": "b39b1aee-a5e0-46b7-a293-45e7893e03ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1803: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_Lsk7UwFMw_f"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./kepler-model\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    remove_unused_columns=False,  # <<< this is important!\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "72bbd495b81a4a7dafbd00980bcb6206",
            "f38861ac54974452b6221686a0076a79",
            "71fedd59de234625b4ee085e8efbf43b",
            "81e54ae318ac4c7d9715683b2f1d9ccb",
            "fd5b383763564405ba42b302a56f45fd",
            "e9b131fdcf0b46ab89b90cc1d4f55d68",
            "ede1bf5c26614961b6bf502bc5b819de",
            "ba55230231484e9abf90b9d61fe49ac7",
            "18c631a9a1274db79a0298a5bf3c73e0",
            "2c187aa5f4a04d99927ff2f22d163fe4",
            "bf8944a799b7427bb93c8b2b12e775d6"
          ]
        },
        "id": "mz467XKXdSgX",
        "outputId": "60370ae1-9897-4488-86db-a1bf4790e22c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72bbd495b81a4a7dafbd00980bcb6206",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/554 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    args=training_args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UxSwm4ZC66lK",
        "outputId": "3843bf91-df57-4c2e-d060-b9b43950ceca"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='504' max='831' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [504/831 1:02:12 < 40:31, 0.13 it/s, Epoch 1.82/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.602300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.400100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.277300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.242000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.233400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.269900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.218300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.275200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.191000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.283900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.261000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.238500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.241100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.252200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.220100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.211900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.234200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.262100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.203600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.257900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.200600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.193600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.217400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.160400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.224700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.213100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.197900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.147100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.157800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.160600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.157000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.156300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.147500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.136000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.141700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.149800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.131100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.159600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.112500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.143900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.139000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.113400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.156300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.139100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.146100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.133600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.161700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='831' max='831' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [831/831 1:43:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.602300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.400100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.277300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.242000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.233400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.269900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.218300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.275200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.191000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.283900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.237200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.261000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.238500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.241100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.252200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.220100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.211900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.234200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.262100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.203600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.257900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.200600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.193600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.217400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.160400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.224700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.213100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.197900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.147100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.157800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.160600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.157000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.156300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.147500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.136000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.141700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.149800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.131100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.159600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.112500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.143900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.139000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.113400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.156300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.133900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.139100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.146100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.133600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.116900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.161700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.114400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.156600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.143200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.160400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.134800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.119100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.110400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.100800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.090900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.092900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.106300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.088300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.108100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.075800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.087000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.107100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>0.077600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>0.104000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>0.087200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.102400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>0.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.111100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>0.085300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>0.100900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.087600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>0.097100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>0.090400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>0.105000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>0.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.078200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>0.099500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>0.100200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>0.084500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=831, training_loss=0.18713862801286718, metrics={'train_runtime': 6208.1788, 'train_samples_per_second': 0.268, 'train_steps_per_second': 0.134, 'total_flos': 108568799870976.0, 'train_loss': 0.18713862801286718})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()  # Now it's called on an instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT0vjETQ12-5",
        "outputId": "203ff837-b113-4e81-c26b-79c64684eafb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('jarvis_lora_model/tokenizer_config.json',\n",
              " 'jarvis_lora_model/special_tokens_map.json',\n",
              " 'jarvis_lora_model/vocab.json',\n",
              " 'jarvis_lora_model/merges.txt',\n",
              " 'jarvis_lora_model/added_tokens.json',\n",
              " 'jarvis_lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# saving the model\n",
        "trainer.model.save_pretrained(\"lora_model2\")\n",
        "tokenizer.save_pretrained(\"lora_model2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJjFLlpmbEzx"
      },
      "source": [
        "saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n37S-6ada2FY",
        "outputId": "bdddd1eb-20fa-46de-ac23-2bc810ea0fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JlAT5PeRa2I9"
      },
      "outputs": [],
      "source": [
        "save_directory = \"/content/drive/MyDrive/KeplerModel7\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-IOTB2c7a6hv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(save_directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOYlo9Aja9Ep",
        "outputId": "7700207b-adcd-4321-eca1-e3dff342711d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/KeplerModel7/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/KeplerModel7/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/KeplerModel7/vocab.json',\n",
              " '/content/drive/MyDrive/KeplerModel7/merges.txt',\n",
              " '/content/drive/MyDrive/KeplerModel7/added_tokens.json',\n",
              " '/content/drive/MyDrive/KeplerModel7/tokenizer.json')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_X2kXEQLzP7",
        "outputId": "f1b72977-926c-4568-d6a7-62e94b5a524e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"Model saved:\", os.path.exists(\"/content/drive/MyDrive/KeplerModel7\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-xUtrhbbJ0I"
      },
      "source": [
        "loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CEaOiiznbMBv"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/KeplerModel7\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/KeplerModel7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lNfdZ0ubUVE"
      },
      "source": [
        "testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VOWT-Adj13Ft"
      },
      "outputs": [],
      "source": [
        "def ask_kepler(prompt, max_new_tokens=100):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se5mWvWn13Jj",
        "outputId": "cc1c43c0-cf47-4e36-96f0-b5c14dda67db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### User: hey i am feeling low .\n",
            "### kepler: Flaws aren't failures \u00e2\u20ac\u201d they're features. They make you human, not defective.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"### User: hey i am feeling low .\\n### kepler:\"\n",
        "response = ask_kepler(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Rgn_lrCBnI"
      },
      "source": [
        "trying to Fine tuning LLM with hugging face dataset but because of time consumption i am not excuting the training of model , but here is the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pBvYczMKC-I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhr6RmScN3Xy",
        "outputId": "1e487804-416e-4108-cf35-a44d0f372af3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# using hugging face dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "df = pd.read_csv(r\"hf://datasets/Algorithmic-Human-Development-Group/Multilingual-Therapy-Dialogues/SAT_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsRGVXcjnZWy"
      },
      "outputs": [],
      "source": [
        "# extracting columns\n",
        "dff = df[['Patient','Therapist']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6D9BO8unZZP"
      },
      "outputs": [],
      "source": [
        "# Initialize list to store processed conversations\n",
        "conversations = []\n",
        "\n",
        "# Iterate over rows and extract prompt-response pairs\n",
        "for i in range(len(dff) - 1):\n",
        "        user_msg = dff.loc[i, 'Patient']\n",
        "        jarvis_msg = dff.loc[i + 1, 'Therapist']\n",
        "        conversations.append({\n",
        "            \"prompt\": f\"User: {user_msg}\",\n",
        "            \"completion\": f\"Jarvis: {jarvis_msg}\"\n",
        "        })\n",
        "\n",
        "# Convert to DataFrame or JSON\n",
        "conv_df = pd.DataFrame(conversations)\n",
        "conv_df.to_json(\"formatted_dataset.jsonl\", orient=\"records\", lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn6teuKNstK4"
      },
      "outputs": [],
      "source": [
        "# droping dublucates\n",
        "conv_df = conv_df[['prompt','completion']].drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXJ1FHbBv50L"
      },
      "outputs": [],
      "source": [
        "# droping nan values\n",
        "conv_df = conv_df[['prompt','completion']].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYYOZljvwL2i"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Clean and strip any unwanted prefixes\n",
        "conv_df[\"prompt\"] = conv_df[\"prompt\"].str.replace(\"User:\\s*\", \"\", regex=True).str.strip()\n",
        "conv_df[\"completion\"] = conv_df[\"completion\"].str.replace(\"Jarvis:\\s*\", \"\", regex=True).str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fcioY7q9w3WS",
        "outputId": "e34226c9-d42d-4583-c2b6-8a76e673824e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"conv_df\",\n  \"rows\": 5453,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1470,\n        \"samples\": [\n          \"I have been with my husband for almost 7 years. We got engaged a little after 5 years of being together. I had always been clear that I wanted to get married and I sadly would drop hints about how i wanted him to propose. \\nWhen he did propose it was during a random vacation that I had planned. I was happy but I couldn't help feeling disappointed too.\\nI had told him numerous times before that I wanted him to do it in front of my friends and family. I know it sounds dumb to be upset but I couldn't help how I was feeling.\\nWe are now married but the wedding and ring were also far from what I wanted and it wasn't due to lack of funds.  I know this is all material and the marriage is the most important thing but I cant help but get jealous and envious every time I see someone get a proposal or wedding that I had wanted.\\nI cant help my anger because I know we only get one proposal and one wedding. What I wanted will never happen.\\nI have been working on my feelings for the past year and half to get over it. I try to focus on our marriage but every time I see someone have the best proposals and weddings I get upset.\\nI know it is selfish and I know its petty but I just can't control it. It's ruining our relationship because I constantly think about it. Plus, I get mad at him for small things because I am trying to hide the fact that I am so disappointed. \\nWhy can't I move on?\",\n          \"Yeah, I almost felt like I was gonna be ill. I was so stressed that day.\",\n          \"Bye then\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"completion\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3174,\n        \"samples\": [\n          \"Hello in Jacksonville,\\u00a0It sounds like you are struggling with motivation to either take or study for a test. \\u00a0There could be several different causes. \\u00a0If you were being seen at my practice, I would ask you to describe your self-talk when engaging in these activities, during the different phases ie. in beginning, after a few days, and after few weeks. \\u00a0Negative self-talk leads to increased disinterest and eventually tasks not being completed. \\u00a0It is great that you recognize that you have the tendency to not complete tasks that you start. \\u00a0Some questions that would be great to explore with a therapist are:\\u00a0how often you start and stop tasks without completing them?how you are feeling when you choose to start/ stop a project/task?how many tasks do you complete? \\u00a0Sometimes we need to recognize list our accomplishments so that they do not go unnoticed. \\u00a0\\u00a0Do you ever feel like you are working against yourself?A licensed counselor in Jacksonville will be able to asses you and rule out or diagnose self-sabotaging, depression, anxiety or other possible contributing factors. \\u00a0Remember to continue to provide yourself daily motivation and encouragement towards your goals.\",\n          \"Consider yourself quite normal for feeling overwhelmed and depressed about your parents divorce. \\u00a0 This is the most natural way to feel at this time.Depending on how old you are, and whether you live under their roof, \\u00a0are dependent on their support, and are either part of the decision or not, of with whom and where you will live, start considering these points.How did you find out about the upcoming divorce?Are either of your parents reluctant to answer your questions or is it clear that neither of them want to talk about anything with you?Whatever your fears and questions about your own future, these are all real. \\u00a0It is necessary for you to know about your basic future.If you are living on your own and the main problem is your inner adjustment that your family structure is completely changing, then probably a good therapist would be a great help to you now, to clarify these tensions.Sending lots of good wishes for an easy resolution to your new path!\",\n          \"If the person doesn't see themselves getting drunk and out of control, and instead continues to drink. \\u00a0 Often along with this the alcoholic person minimizes or dismisses your concern that they're drinking more than for social fun.Also if someone manages their life around drinking as their priority. \\u00a0 Someone who is physically addicted to alcohol will want to drink even when there is no social activity going on or they are not in a circumstance in which relaxing with a drink is possible.Often the drive is so strong the person will keep their drinking secret if they know others wouldn't ordinarily drink at that time of day.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "conv_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9c2b08f5-9682-45d5-853d-ca113f815efc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Umm I am kind of doing, I'm feeling a little b...</td>\n",
              "      <td>stressed?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yeah, I feel like I have a lot on my plate. I ...</td>\n",
              "      <td>What kind of test?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It's like an aptitude test. It has like math p...</td>\n",
              "      <td>Now, that's a job that you've been interested ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yes. Yes. So I've been just feeling a lot of a...</td>\n",
              "      <td>so you know the material on this test pretty w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes.</td>\n",
              "      <td>But the feelings and that the physiological re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7168</th>\n",
              "      <td>What are the basic skills a good counselor nee...</td>\n",
              "      <td>1) An awareness of their own incompetence and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7172</th>\n",
              "      <td>What are the basic skills a good counselor nee...</td>\n",
              "      <td>Each client brings their own style they like t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7173</th>\n",
              "      <td>What are some difficulties that a counselor ca...</td>\n",
              "      <td>Although many clients have the capacity to be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7174</th>\n",
              "      <td>What are some difficulties that a counselor ca...</td>\n",
              "      <td>I usually don't label a client as \"difficult\" ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7175</th>\n",
              "      <td>What are some difficulties that a counselor ca...</td>\n",
              "      <td>Dang right!\u00c2\u00a0 :)Heh heh, and correct me if I'm ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5453 rows \u00c3\u2014 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c2b08f5-9682-45d5-853d-ca113f815efc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c2b08f5-9682-45d5-853d-ca113f815efc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c2b08f5-9682-45d5-853d-ca113f815efc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-66164f8b-a099-4b54-aa59-f7d062534603\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66164f8b-a099-4b54-aa59-f7d062534603')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-66164f8b-a099-4b54-aa59-f7d062534603 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fbe921a2-8603-41fb-993e-3384bfd82c5e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('conv_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fbe921a2-8603-41fb-993e-3384bfd82c5e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('conv_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                 prompt  \\\n",
              "0     Umm I am kind of doing, I'm feeling a little b...   \n",
              "1     Yeah, I feel like I have a lot on my plate. I ...   \n",
              "2     It's like an aptitude test. It has like math p...   \n",
              "3     Yes. Yes. So I've been just feeling a lot of a...   \n",
              "4                                                  yes.   \n",
              "...                                                 ...   \n",
              "7168  What are the basic skills a good counselor nee...   \n",
              "7172  What are the basic skills a good counselor nee...   \n",
              "7173  What are some difficulties that a counselor ca...   \n",
              "7174  What are some difficulties that a counselor ca...   \n",
              "7175  What are some difficulties that a counselor ca...   \n",
              "\n",
              "                                             completion  \n",
              "0                                             stressed?  \n",
              "1                                    What kind of test?  \n",
              "2     Now, that's a job that you've been interested ...  \n",
              "3     so you know the material on this test pretty w...  \n",
              "4     But the feelings and that the physiological re...  \n",
              "...                                                 ...  \n",
              "7168  1) An awareness of their own incompetence and ...  \n",
              "7172  Each client brings their own style they like t...  \n",
              "7173  Although many clients have the capacity to be ...  \n",
              "7174  I usually don't label a client as \"difficult\" ...  \n",
              "7175  Dang right!\u00c2\u00a0 :)Heh heh, and correct me if I'm ...  \n",
              "\n",
              "[5453 rows x 2 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29LCwb-PnZcE"
      },
      "outputs": [],
      "source": [
        "with open(\"jarvis_finetune_dataset.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for _, row in conv_df.iterrows():          # _ means \"I don't care about the row index\".\n",
        "        json.dump({\"prompt\": row[\"prompt\"], \"completion\": row[\"completion\"]}, f)\n",
        "        f.write(\"\\n\")                      # row is a Pandas Series that contains one full row: both the \"prompt\" and \"response\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLKbfBTy0kJY",
        "outputId": "20d865f5-98f0-48ef-90d3-334abced90e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"prompt\": \"Umm I am kind of doing, I'm feeling a little bit stressed out\", \"completion\": \"stressed?\"}\n",
            "\n",
            "{\"prompt\": \"Yeah, I feel like I have a lot on my plate. I have this test that I have to take for work.\", \"completion\": \"What kind of test?\"}\n",
            "\n",
            "{\"prompt\": \"It's like an aptitude test. It has like math problems on it and like scenarios in order for me to move up to the system manager position.\", \"completion\": \"Now, that's a job that you've been interested in for a while.\"}\n",
            "\n",
            "{\"prompt\": \"Yes. Yes. So I've been just feeling a lot of anxiety about taking the test and then they actually scheduled for me to take the test. And I want and I just got really overwhelmed. And I started like I felt my heart was racing. I felt like I wish my hands were shaking. And I just really couldn't concentrate on the test. Even though the night before me and my friend that practice problems, and I knew all the answers with no proper like, I didn't miss any of the questions\", \"completion\": \"so you know the material on this test pretty well?\"}\n",
            "\n",
            "{\"prompt\": \"yes.\", \"completion\": \"But the feelings and that the physiological response to heart rate and sweating, that feelings of anxiety plus those physiological responses they got in the way of you completing it, like you were unable to complete it.\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"jarvis_finetune_dataset.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for _ in range(5):\n",
        "        print(f.readline())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZwKdjYx0kL2",
        "outputId": "4794d37c-1b70-4601-d83b-a0fd684ae727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt        0\n",
            "completion    0\n",
            "dtype: int64\n",
            "Empty DataFrame\n",
            "Columns: [prompt, completion]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [prompt, completion]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# checking null values\n",
        "print(conv_df.isnull().sum())\n",
        "print(conv_df[conv_df[\"prompt\"].str.strip() == \"\"])\n",
        "print(conv_df[conv_df[\"completion\"].str.strip() == \"\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voJfWhNxi2cG",
        "outputId": "09b0d211-ab78-41c9-a630-94a9b753445c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'prompt': \"Umm I am kind of doing, I'm feeling a little bit stressed out\", 'completion': 'stressed?'}\n",
            "Total samples: 5453\n"
          ]
        }
      ],
      "source": [
        "# converting the dataset into dict\n",
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "# 1. Read file lines\n",
        "with open(\"jarvis_finetune_dataset.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# 2. Parse JSON objects\n",
        "records = [json.loads(line) for line in lines if line.strip()]\n",
        "\n",
        "# 3. Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_list(records)\n",
        "\n",
        "# 4. Quick examine\n",
        "print(dataset[0])\n",
        "print(\"Total samples:\", len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wedaavM5Ivb",
        "outputId": "f1f3226b-7a25-4e31-df42-befa0ccdb8e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'prompt': \"Umm I am kind of doing, I'm feeling a little bit stressed out\", 'completion': 'stressed?'}\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "06bdae7374ac40e79151ff4a8f5d8b7f",
            "f7e1561b931f4a8c8e94cf6ddb49075c",
            "26b982423a7448a39704233466d0dbb4",
            "cec735c857e14a78a4bfd094ea779e7a",
            "c09249333776439b893bc8d692324a52",
            "50aecd55a6c1407fbda41e89c00e652c",
            "94da0fcaf6554eba9b29396a3452cca7",
            "c1aed4f621834b43a722f602534deb33",
            "8bc6e9752a804fb69e0ac5bc18fd1770",
            "acaf064fc5724493aa2fdd2a5c76742a",
            "44c4d5d99b7f49b4ab914e64183c76ba"
          ]
        },
        "id": "3kFQY84pwtMT",
        "outputId": "2c9ae50e-e592-49fe-8b9e-929e144dacae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06bdae7374ac40e79151ff4a8f5d8b7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5453 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# now convert dataset sytax into model syntax\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(example):\n",
        "    input_enc = tokenizer(example[\"prompt\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "    output_enc = tokenizer(example[\"completion\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_enc[\"input_ids\"],\n",
        "        \"attention_mask\": input_enc[\"attention_mask\"],\n",
        "        \"labels\": output_enc[\"input_ids\"]\n",
        "    }\n",
        "\n",
        "dataset = dataset.map(tokenize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UkPd2QZxnAP"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ijvj3bz5I_p"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "90b20320c44d49769a7e09ac6641ff99",
            "81b8c6a54190430a809dc3f2f52e719d",
            "f807ceafbacd40a59ea3d0535b4434b7",
            "e07d3c922d2140bd89467ebbaed0cdc2",
            "edd64a0f31f24b93a7dbf1f11a345c41",
            "bc30a808e3334765977b4ff5a2f489ef",
            "f839eacf29a8486582649ef0cc14b7c2",
            "18d1ec3229744ea1bb70ed43ed488e27",
            "9e761694dfed43dabe9a3406ed64988c",
            "4933472eebee4675b37f287af7da7782",
            "6f1edbc75025425ab5f59e417455796e",
            "758a380bc0384b75b524cfbc617f691a",
            "f13130afb8034c95887e78686d5541f9",
            "2894fa9655e747e68d14aa3c819c4ff6",
            "e91816a0b1d546f9a240f0fab705ea40",
            "f50801847f5d46289dfea54413ad8ad5",
            "5ab26af299b54f12a881a261e8e89123",
            "ce9d7a853c5647e3aa45bcb6ce98fa9e",
            "021ed247e78e46b18e8e90cdefac39d9",
            "0f35827f435a4122baafd04ebf981457",
            "af21f3d4d6714442a6b4ef498e3b3553",
            "1fe66206f36744cbbc2dbb28aff1a017",
            "902c0f79d74742a680874a15c992b7e1",
            "aa78255793f149c8aa67d68d4702f095",
            "93acf041534d42d2bbacbf549fc2226e",
            "f6ca1a396b61418aab026ace839272b3",
            "d1abf02e6f074f129b13dbd93cec8de6",
            "5a09b20949ec4d57805bfb2ec709ab8c",
            "c29559b4757d4dccb46282f0a8f9f08f",
            "5ead2e82d3f442b8bcf97d428ce25177",
            "bc0e4e0889524c33890329a23acc4df3",
            "f54d9e507a004a74b4fd99280d8b6e74",
            "5468f52a50bd4c0c87691cf38c2a310b"
          ]
        },
        "id": "hOwMPWHBe6YM",
        "outputId": "14694a02-a15c-429f-8900-d1e2bddd437d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90b20320c44d49769a7e09ac6641ff99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "758a380bc0384b75b524cfbc617f691a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "902c0f79d74742a680874a15c992b7e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load tokenizer and model\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "\n",
        "# Model & Tokenizer\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model.gradient_checkpointing_enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XYi5S3IfFws"
      },
      "outputs": [],
      "source": [
        "# Setup LoRA config\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q\", \"v\"],  # typical for T5\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsZ-JJsDfQ56"
      },
      "outputs": [],
      "source": [
        "# finializing the model\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAV0VoTTq2eQ"
      },
      "outputs": [],
      "source": [
        "#  Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    output_dir=\"./results\",\n",
        "    save_total_limit=2,\n",
        "    logging_steps=10,\n",
        "    fp16=False,\n",
        "    save_steps=500,  # Saves every 500 steps\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWsPYIhsflp0",
        "outputId": "80ed9600-77c2-4070-ea73-1e6a234e4579"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-18-4230928724.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "#  Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pxWBWz9b2Kcs",
        "outputId": "5c64905c-a5d5-418c-8dbc-b4ab9d630e9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4092' max='4092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4092/4092 5:36:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>14.399000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>15.655200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>15.196600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>14.206600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>12.273300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>9.172900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>10.925500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>10.493000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>12.771800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>11.465100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>7.830900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>8.045500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>8.261300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>7.399700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>7.958500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>6.335600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>5.726500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>5.442900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>5.490300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>5.216200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>4.545000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>5.160900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>4.376700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>4.689300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.547100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>4.232800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>4.277900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>4.346700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>4.325900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.372600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>4.105500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>4.173600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>4.339800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>4.175500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.082500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>4.150700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>4.105300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>4.269500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>4.088900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.038600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>3.996000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>4.012600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>3.989700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>4.021700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>4.114400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>3.875600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>3.986300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>3.954800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>4.052500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.134700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>4.116400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>4.091300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>3.972800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>3.934100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.929600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>3.879100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>3.991000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>3.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>4.127200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.962700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>3.861500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>3.885900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>4.017700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>3.931700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.784700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>3.941300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>3.757600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>3.839500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>3.879200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.913600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>3.839900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>3.832400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>3.773100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>3.942700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.897600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>3.803200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>3.747400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>3.810300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>3.829700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.790000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>3.806400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>3.830500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>3.803800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>3.801500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.844100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>3.837400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>3.760200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>3.862300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>3.785100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.856400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>3.691100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>3.749700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>3.729500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>3.819000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>3.818400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>3.788400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>3.835200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>3.863200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>3.741300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.746100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>3.728100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>3.751400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>3.759200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>3.832800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>3.745700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>3.781000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>3.788100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>3.741800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>3.732000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>3.720600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>3.849500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>3.767000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>3.719800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>3.759300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>3.714200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>3.751200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>3.719500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>3.769000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.741000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>3.736400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>3.748600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>3.684000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>3.794700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>3.696900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>3.607400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>3.638600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>3.701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>3.683100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>3.658800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>3.555900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>3.683800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>3.754600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>3.711200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>3.690300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>3.703300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>3.487300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>3.612000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>3.704300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>3.718200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>3.639100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>3.695600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>3.655100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>3.543500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>3.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>3.637300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>3.728600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>3.639800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>3.767700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.593200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>3.567600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>3.573400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>3.642400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>3.700500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>3.573000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>3.679000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>3.640200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>3.658700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>3.712700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>3.581300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>3.583700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>3.513400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>3.606600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>3.598500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>3.719500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>3.538700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>3.610600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>3.595900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>3.621000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>3.672400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>3.624100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>3.588900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>3.592600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>3.606600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>3.606800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>3.586600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>3.644000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>3.665100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>3.510900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>3.567100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>3.622100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>3.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>3.566900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>3.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>3.561500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>3.491200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>3.522500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>3.587400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>3.535200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>3.639600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>3.585200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>3.575000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>3.593000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>3.503800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>3.660800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>3.528300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>3.575100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>3.579100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>3.534500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.529200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>3.608700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>3.567000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>3.532900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>3.630200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>3.564300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>3.524600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>3.609000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>3.503700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>3.539400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>3.515500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>3.519200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>3.465600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>3.541400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>3.538100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>3.472300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>3.492900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>3.530100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>3.492500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>3.461400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>3.523900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>3.556900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>3.536000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>3.516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>3.614300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>3.511500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>3.502000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>3.491600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>3.592400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>3.534000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>3.572500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>3.489100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>3.536600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>3.506800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>3.544800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>3.505700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>3.558300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>3.476200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>3.579600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>3.488900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>3.541900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>3.496000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>3.422500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>3.402700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>3.505000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>3.497600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2460</td>\n",
              "      <td>3.434600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>3.426300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2480</td>\n",
              "      <td>3.488400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2490</td>\n",
              "      <td>3.420800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>3.465700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2510</td>\n",
              "      <td>3.480200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2520</td>\n",
              "      <td>3.502200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2530</td>\n",
              "      <td>3.593100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2540</td>\n",
              "      <td>3.542900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>3.498300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2560</td>\n",
              "      <td>3.420500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2570</td>\n",
              "      <td>3.539700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2580</td>\n",
              "      <td>3.474800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2590</td>\n",
              "      <td>3.499500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>3.421300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2610</td>\n",
              "      <td>3.497700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2620</td>\n",
              "      <td>3.494100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2630</td>\n",
              "      <td>3.531500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2640</td>\n",
              "      <td>3.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>3.491900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2660</td>\n",
              "      <td>3.468900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2670</td>\n",
              "      <td>3.480400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2680</td>\n",
              "      <td>3.474400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2690</td>\n",
              "      <td>3.418700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>3.576200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2710</td>\n",
              "      <td>3.556300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2720</td>\n",
              "      <td>3.368100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2730</td>\n",
              "      <td>3.303100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2740</td>\n",
              "      <td>3.431400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>3.441000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2760</td>\n",
              "      <td>3.521100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2770</td>\n",
              "      <td>3.467200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2780</td>\n",
              "      <td>3.499000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2790</td>\n",
              "      <td>3.452000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>3.551400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2810</td>\n",
              "      <td>3.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2820</td>\n",
              "      <td>3.472200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2830</td>\n",
              "      <td>3.574300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2840</td>\n",
              "      <td>3.546300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>3.516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2860</td>\n",
              "      <td>3.329400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2870</td>\n",
              "      <td>3.556500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2880</td>\n",
              "      <td>3.456700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2890</td>\n",
              "      <td>3.492300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>3.514500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2910</td>\n",
              "      <td>3.457500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2920</td>\n",
              "      <td>3.472100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2930</td>\n",
              "      <td>3.348600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2940</td>\n",
              "      <td>3.500800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>3.547100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2960</td>\n",
              "      <td>3.482000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2970</td>\n",
              "      <td>3.529000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2980</td>\n",
              "      <td>3.398800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2990</td>\n",
              "      <td>3.462300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>3.481500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3010</td>\n",
              "      <td>3.582100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3020</td>\n",
              "      <td>3.462100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3030</td>\n",
              "      <td>3.400600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3040</td>\n",
              "      <td>3.360900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>3.505200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3060</td>\n",
              "      <td>3.485500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3070</td>\n",
              "      <td>3.420200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3080</td>\n",
              "      <td>3.483800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3090</td>\n",
              "      <td>3.531800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>3.494300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3110</td>\n",
              "      <td>3.441000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3120</td>\n",
              "      <td>3.487100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3130</td>\n",
              "      <td>3.483400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3140</td>\n",
              "      <td>3.413700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>3.413100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3160</td>\n",
              "      <td>3.361200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3170</td>\n",
              "      <td>3.543700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3180</td>\n",
              "      <td>3.459400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3190</td>\n",
              "      <td>3.382900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>3.454600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3210</td>\n",
              "      <td>3.413400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3220</td>\n",
              "      <td>3.459000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3230</td>\n",
              "      <td>3.512000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3240</td>\n",
              "      <td>3.485600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>3.450100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3260</td>\n",
              "      <td>3.594400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3270</td>\n",
              "      <td>3.493500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3280</td>\n",
              "      <td>3.448700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3290</td>\n",
              "      <td>3.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>3.486300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3310</td>\n",
              "      <td>3.482700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3320</td>\n",
              "      <td>3.379900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3330</td>\n",
              "      <td>3.485700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3340</td>\n",
              "      <td>3.389600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>3.508300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3360</td>\n",
              "      <td>3.395800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3370</td>\n",
              "      <td>3.389900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3380</td>\n",
              "      <td>3.412300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3390</td>\n",
              "      <td>3.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>3.407300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3410</td>\n",
              "      <td>3.353900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3420</td>\n",
              "      <td>3.381800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3430</td>\n",
              "      <td>3.464000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3440</td>\n",
              "      <td>3.464000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>3.358200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3460</td>\n",
              "      <td>3.468800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3470</td>\n",
              "      <td>3.478600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3480</td>\n",
              "      <td>3.534100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3490</td>\n",
              "      <td>3.396600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>3.402100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3510</td>\n",
              "      <td>3.497500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3520</td>\n",
              "      <td>3.413400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3530</td>\n",
              "      <td>3.502700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3540</td>\n",
              "      <td>3.455600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>3.499900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3560</td>\n",
              "      <td>3.471000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3570</td>\n",
              "      <td>3.364900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3580</td>\n",
              "      <td>3.461900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3590</td>\n",
              "      <td>3.312700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>3.422800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3610</td>\n",
              "      <td>3.474600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3620</td>\n",
              "      <td>3.382900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3630</td>\n",
              "      <td>3.455700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3640</td>\n",
              "      <td>3.411000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>3.545700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3660</td>\n",
              "      <td>3.491900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3670</td>\n",
              "      <td>3.461500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3680</td>\n",
              "      <td>3.438500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3690</td>\n",
              "      <td>3.463700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>3.520600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3710</td>\n",
              "      <td>3.416400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3720</td>\n",
              "      <td>3.574000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3730</td>\n",
              "      <td>3.505200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3740</td>\n",
              "      <td>3.393000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>3.534800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3760</td>\n",
              "      <td>3.474000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3770</td>\n",
              "      <td>3.448500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3780</td>\n",
              "      <td>3.505600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3790</td>\n",
              "      <td>3.468800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>3.463900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3810</td>\n",
              "      <td>3.524000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3820</td>\n",
              "      <td>3.447500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3830</td>\n",
              "      <td>3.369100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3840</td>\n",
              "      <td>3.577600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>3.388400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3860</td>\n",
              "      <td>3.514400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3870</td>\n",
              "      <td>3.408200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3880</td>\n",
              "      <td>3.413000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3890</td>\n",
              "      <td>3.401700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>3.428400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3910</td>\n",
              "      <td>3.558500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3920</td>\n",
              "      <td>3.425100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3930</td>\n",
              "      <td>3.404400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3940</td>\n",
              "      <td>3.371300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>3.445400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3960</td>\n",
              "      <td>3.479500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3970</td>\n",
              "      <td>3.458300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3980</td>\n",
              "      <td>3.432100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3990</td>\n",
              "      <td>3.480800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.357500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4010</td>\n",
              "      <td>3.515300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4020</td>\n",
              "      <td>3.461900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4030</td>\n",
              "      <td>3.288100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4040</td>\n",
              "      <td>3.485800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>3.432800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4060</td>\n",
              "      <td>3.393700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4070</td>\n",
              "      <td>3.485500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4080</td>\n",
              "      <td>3.446100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4090</td>\n",
              "      <td>3.393700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4092, training_loss=3.923347518707417, metrics={'train_runtime': 20224.3381, 'train_samples_per_second': 0.809, 'train_steps_per_second': 0.202, 'total_flos': 764568412618752.0, 'train_loss': 3.923347518707417, 'epoch': 3.0})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcM05UOl6pC0",
        "outputId": "f3542647-8187-4a87-ebcc-88f97f673c26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/bestLLM_trainer2/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/bestLLM_trainer2/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/bestLLM_trainer2/spiece.model',\n",
              " '/content/drive/MyDrive/bestLLM_trainer2/added_tokens.json',\n",
              " '/content/drive/MyDrive/bestLLM_trainer2/tokenizer.json')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/bestLLM_model2')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/bestLLM_trainer2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiFH6-HWIJik"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmFyyns27MN1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGiCx2AG7MQP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQaT2CwH7MSA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEkP8lUl7MUZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ap_OcD5w7MWk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLIPRrMv7MZC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CevAh_SR7Ma-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4VK9K5P7MdF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7Ja9pK97Mfi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7piAusrc7MjX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwruo7ss7Mml"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}